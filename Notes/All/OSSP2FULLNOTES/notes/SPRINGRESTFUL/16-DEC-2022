More into delcarative pipeline structure
#1.
The declarative pipeline starts with pipeline {} and followed by agent

pipeline {
	agent any/none
	stages {
		stage('stage1') {
			agent 'agent1'
		}
		stage('stage2') {
			agent 'agent2'
		}
	}
}
we can declare agent at pipline{} or individual stage level. declaring agent non at the pipeline level forces us to declare agent at individual stage level

#2. In the pipeline we can write post{} block to define one more steps to be executed upon completion of the pipeline or stage. The post block supports post-conditions based on which it will be executed
1. always       = regardless of the status of the execution always the post-block will be executed
2. changed      = execute the post-block only when the pipeline run has a different status from its previous run
3. fixed        = run the post-block only when the current run is successful and previous runs are failed or unstable 
4. regression   = if the current run is failed or unstable or aborted and previous run was successful
5. aborted      = pipeline is aborted manually using GUI
6. failure      = resultedin failure
7. success      = results in success
8. unstable     = The unstable status will be caused due to test failure or code violations. in such case only execute the post-block
9. unsuccessful = if the pipeline or a stage run has not success status then it is called un-successful then execute post-block
10. cleanup = execute the post condition after every post condition completed irrespective of the pipeline status

pipeline {
	agent any
	stages {
		stage('stage1') {
			steps {
				echo 'stage1'
			}
		}
	}
	post {
		always {
			echo 'always execute post block'
		}
	}
}
-----------------------------------------------------------------------------------------------------------------------
Directives
1. environment
environment is a directive used for declaring key=value pair environment variables either at pipeline level or stage level we want

pipeline {
	agent any
	environment {
		k1=v1
		k2=v2
	}
	stages {
		stage("stage1") {
			environment {
				k3=v3
			}
		}
	}	
}
The environment variables declared in the pipeline level are global to the pipeline whereas the stage variables are visible and accessible within that stage only

The environment directive supports special type of helper method credentials() which is used for accessing the pre-defined credentials by using identified we defined in jenkins environment
we can write credentials both at pipeline and stage as well

pipeline {
	agent any
	stages {
		stage('stage1') {
			environment {
				GIT_PASSWORD = credentials('gitHubCredId')
			}
			steps {
				sh 'echo "Git Credentials ${GIT_PASSWORD_USR} and ${GIT_PASSWORD_PSW}"'
			}
		}
	}
}

#2. options
options directive allows us to configure pipeline-specific options within the pipeline itself.
	
1. buildDiscarder
keep the artifacts and console output for specific number of recent pipeline runs only
buildDiscarder(logRotator(numToKeepStr: '3'))

2. checkoutToSubdirectory('subDirectory')
checkout the sourcecode into the subDirectory specified under the workspace

3. disableConcurrentBuilds
disable concurrent builds prevent simulataneous access of shared resources

4. retry
on failure, retry the pipeline the specified number of times 
options {
	retry(3)
}

5. timeout
set a timeout period for the pipeline run
options {
	timeout(time: 1, units: 'HOURS')
}

6. timestamps
prepend all the console outputs generated by the pipeline run with timestamps


#3. parameters
There parameters directive indicates a list of parameters the user should provide while triggering the pipeline.
The parameters the user has supplied can be accessed within the pipeline steps using params.PARAMETER_NAME

There are 5 types of parameters supported
1. string(name: '', defaultValue: '', description: '')
2. text(name: '', defaultValue: '', description: '')
3. booleanParam(name: '', defaultValue: '', description: '')
4. choice(name: '', choices: [], description: '')
5. password(name: '', defaultValue: '', description: '')

#4. triggers
The trigger directive is used for defining the automated ways of triggering the pipeline.
For the pipelines that are integrated with vcs repository, the trigger may not be required, because the pipeline is invoked through web-hooks. 
There are 3 types of triggers we can apply
1. cron
2. pollSCM
3. upstream


1. cron 
A cron-style string to define the regular time interval at which the pipeline has to be triggered
triggers {
	cron('H */4 * * 1-5')
}

MINUTE   HOUR    DOM                MONTH               DOW
(0-59)   (0-23)  day of the Month   The 12months (1-12) The day of the week
                 (1-31)                                 (0-7) where 0 & 7 Sunday
H can be used in place of "*" to indicate schedule task to produce even load on the system. (h for HASH)
	
cron('45 8 * * 1-6')
cron('H      H     1,15   1-11    1-5')	= execute the job on 1,15 of each month except December and if it is not saturday or sunday
      |      |     |      |       |
	    Minute Hour  DOM    Month  DOW
 
2. pollSCM
it also accepts cron style expression indicating the interval time it has to goto SCM repository to check for new commits if exists then triggers the pipeline


3. upstream
triggers the pipeline execute basedon the another job
triggers {
	upstream(upstreamProjects: 'job1, job2', threshold: hudson.model.Result.SUCCESS)
}

#5. tools
A directive used for defining auto install of the tool and put on the PATH of the execution. This directive is ignored when we specify the agent none

Before using the tools directive, we need to add the tool into the jenkins system under globalToolConfiguration defining the tool to be auto-installed.
	
when we refer the specified tool version in pipeline through tool directive, the jenkins system will install that tool and make it available under PATH

pipeline {
	agent any
	tools {
		maven 'mvn-3.83.6'
	}
	stages {
		stage('mvn') {
			steps {
				sh 'mvn --version'
			}
		}
	}
}

#6. input
The input directive on stage allows us to prompt for input, using the input step. The stage will be paused after the options have been applied before the agent{} block for the stage or evaluating when conditions of the stage.
	
if the input is approvedthen the stage will be continued, Any parameters provided aspart of the input submission will be available in the environment for the rest of the stage.
	
attributes:-
1. message
2. id
3. ok
4. submitter
5. submitterParameter (optional)
	
input {
	message "Do you want continue"
	ok "Yes, we should"
	submitter "bob, alex"		
}	


pipeline {
    agent any
    stages {
        stage('input with parametes') {
            input {
                message 'enter age'
                ok 'Yes'
                parameters {
                    string(name: 'age', defaultValue: '0', description: 'Enter age')
                }
            }
            steps {
                sh 'echo "Your age is ${age}"'
            }
        }
    }
}
------------------------------------------------------------------------------------------------------------------------
#7. when directive
The when directive allows the pipeline to determine when the stage should be executed dependening on the given when condition.
	
we can write nested when conditions, if more than one when conditions are nested then all must the return true to execute the stage. we can build complex nested when conditions using not, allOf, or anyOf structures

Built-In Conditions:
1. branch
when {
	branch 'master'
}

2. equals
when the expected value is equal to actual value
when {
	equals expected: 2, actual: currentBuild.number
}

3. allOf
execute the stage when all the nested conditions are true
allOf{
	branch 'master'; environment name: 'DEPLOY_TO', value: 'production'
}

4. anyOf
execute the stage when any one of the condition is true
	
anyOf {
	{branch 'master'; branch 'develop'}
}

By default the when condition will be evaluated after the agent has entered into stage, we can change this behaviour using beforeAgent

pipeline {
    agent any
    stages {
        stage('when condition') {
            input {
                message 'Enter age:'
                ok 'ok'
                parameters {
                    string(name: 'age', defaultValue: 0, description: 'age:')
                }
            }
            when{
                equals expected: '18', actual: "${age}"
            }
        }
    }
}

#7. script
The script step takes a scripted pipeline and executes that in the declarative pipeline. it is not recommended to write script step in declarative pipeline.
	
pipeline {
	agent any
	stages {
		stage('scripted') {
			steps {
				echo 'scripted code begins'
				script {
					for(int i=0;i<10;i++) {
						echo "${i}"
					}
				}
			}
		}
	}
}	
	

1. variables
2. parameters
3. credentials
4. triggers
5. pipeline options
6. when
7. input
8. tools
9. post block
10. script

	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	




































































































































































